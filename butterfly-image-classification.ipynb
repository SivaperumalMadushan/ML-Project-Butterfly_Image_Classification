{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12289446,"sourceType":"datasetVersion","datasetId":3442424}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Step 1: Import necessary libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nimport cv2\nfrom PIL import Image\nimport os\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-25T02:32:19.186075Z","iopub.execute_input":"2025-09-25T02:32:19.186391Z","iopub.status.idle":"2025-09-25T02:32:44.974477Z","shell.execute_reply.started":"2025-09-25T02:32:19.186360Z","shell.execute_reply":"2025-09-25T02:32:44.973146Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset_path = '/kaggle/input/butterfly-image-classification' \ntrain_csv_path = os.path.join(dataset_path, 'Training_set.csv')\ntest_csv_path = os.path.join(dataset_path, 'Testing_set.csv')\ntrain_dir = os.path.join(dataset_path, 'train')\ntest_dir = os.path.join(dataset_path, 'test')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T02:32:49.395871Z","iopub.execute_input":"2025-09-25T02:32:49.396190Z","iopub.status.idle":"2025-09-25T02:32:49.401721Z","shell.execute_reply.started":"2025-09-25T02:32:49.396166Z","shell.execute_reply":"2025-09-25T02:32:49.400600Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 3: Load the training CSV and explore the data\ntrain_df = pd.read_csv(\"/kaggle/input/butterfly-image-classification/Training_set.csv\")\nprint(\"Training set shape:\", train_df.shape)\nprint(\"\\nFirst few rows:\")\nprint(train_df.head())\nprint(\"\\nUnique classes:\", train_df['label'].nunique())\nprint(\"Class distribution:\")\nprint(train_df['label'].value_counts().head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T02:33:48.824807Z","iopub.execute_input":"2025-09-25T02:33:48.825109Z","iopub.status.idle":"2025-09-25T02:33:48.844757Z","shell.execute_reply.started":"2025-09-25T02:33:48.825088Z","shell.execute_reply":"2025-09-25T02:33:48.843700Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(12, 6))\nsns.countplot(y='label', data=train_df, order=train_df['label'].value_counts().index[:10])\nplt.title('Top 10 Butterfly Classes Distribution')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T02:34:00.844837Z","iopub.execute_input":"2025-09-25T02:34:00.845130Z","iopub.status.idle":"2025-09-25T02:34:01.251179Z","shell.execute_reply.started":"2025-09-25T02:34:00.845109Z","shell.execute_reply":"2025-09-25T02:34:01.250180Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 4: Encode labels\nlabel_encoder = LabelEncoder()\ntrain_df['label_encoded'] = label_encoder.fit_transform(train_df['label'])\nnum_classes = len(label_encoder.classes_)\nprint(f\"Number of classes: {num_classes}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T02:34:07.135554Z","iopub.execute_input":"2025-09-25T02:34:07.135888Z","iopub.status.idle":"2025-09-25T02:34:07.144059Z","shell.execute_reply.started":"2025-09-25T02:34:07.135861Z","shell.execute_reply":"2025-09-25T02:34:07.142931Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 5: Define image loading and preprocessing function\nIMG_SIZE = (224, 224)  # Standard size for many CNNs; adjust if needed for memory\ndef load_and_preprocess_image(image_path, label):\n    \"\"\"\n    Load image, resize, normalize, and return as numpy array.\n    \"\"\"\n    try:\n        image = cv2.imread(image_path)\n        if image is None:\n            return None\n        image = cv2.resize(image, IMG_SIZE)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB\n        image = image.astype('float32') / 255.0  # Normalize to [0,1]\n        return image, label\n    except Exception as e:\n        print(f\"Error loading {image_path}: {e}\")\n        return None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T02:34:10.144034Z","iopub.execute_input":"2025-09-25T02:34:10.144469Z","iopub.status.idle":"2025-09-25T02:34:10.155451Z","shell.execute_reply.started":"2025-09-25T02:34:10.144431Z","shell.execute_reply":"2025-09-25T02:34:10.154232Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 6: Load training images with preprocessing\n# This may take time (~1000+ images); run on GPU for speed\nprint(\"Loading and preprocessing training images...\")\ntrain_images = []\ntrain_labels = []\n\nfor index, row in train_df.iterrows():\n    image_filename = row['filename']\n    image_path = os.path.join(train_dir, image_filename)\n    result = load_and_preprocess_image(image_path, row['label_encoded'])\n    if result is not None:\n        img, lbl = result\n        train_images.append(img)\n        train_labels.append(lbl)\n\ntrain_images = np.array(train_images)\ntrain_labels = np.array(train_labels)\n\nprint(f\"Loaded {len(train_images)} training images with shape {train_images.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T02:34:15.794392Z","iopub.execute_input":"2025-09-25T02:34:15.794721Z","iopub.status.idle":"2025-09-25T02:35:34.367047Z","shell.execute_reply.started":"2025-09-25T02:34:15.794696Z","shell.execute_reply":"2025-09-25T02:35:34.365982Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 7: One-hot encode labels\ntrain_labels_cat = to_categorical(train_labels, num_classes=num_classes)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T02:35:49.125014Z","iopub.execute_input":"2025-09-25T02:35:49.125404Z","iopub.status.idle":"2025-09-25T02:35:49.131398Z","shell.execute_reply.started":"2025-09-25T02:35:49.125376Z","shell.execute_reply":"2025-09-25T02:35:49.130233Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 8: Split into train and validation sets (80/20)\nX_train, X_val, y_train, y_val = train_test_split(\n    train_images, train_labels_cat, test_size=0.2, random_state=42, stratify=train_labels\n)\nprint(f\"Training set: {X_train.shape[0]} images\")\nprint(f\"Validation set: {X_val.shape[0]} images\")\n\n# Visualize a few sample images\nplt.figure(figsize=(12, 8))\nfor i in range(6):\n    plt.subplot(2, 3, i+1)\n    idx = np.random.randint(0, X_train.shape[0])\n    plt.imshow(X_train[idx])\n    true_label = np.argmax(y_train[idx])\n    plt.title(f\"Class: {label_encoder.inverse_transform([true_label])[0]}\")\n    plt.axis('off')\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T02:35:52.734911Z","iopub.execute_input":"2025-09-25T02:35:52.735233Z","iopub.status.idle":"2025-09-25T02:35:55.174495Z","shell.execute_reply.started":"2025-09-25T02:35:52.735209Z","shell.execute_reply":"2025-09-25T02:35:55.173356Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 9: Data Augmentation (to prevent overfitting)\ndatagen = ImageDataGenerator(\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=True,\n    zoom_range=0.2\n)\ndatagen.fit(X_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T02:37:09.866382Z","iopub.execute_input":"2025-09-25T02:37:09.866708Z","iopub.status.idle":"2025-09-25T02:37:11.415862Z","shell.execute_reply.started":"2025-09-25T02:37:09.866683Z","shell.execute_reply":"2025-09-25T02:37:11.414640Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 10: Build the CNN Model\nmodel = Sequential([\n    # First Conv Block\n    Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3)),\n    BatchNormalization(),\n    MaxPooling2D(2, 2),\n    Dropout(0.25),\n    \n    # Second Conv Block\n    Conv2D(64, (3, 3), activation='relu'),\n    BatchNormalization(),\n    MaxPooling2D(2, 2),\n    Dropout(0.25),\n    \n    # Third Conv Block\n    Conv2D(128, (3, 3), activation='relu'),\n    BatchNormalization(),\n    MaxPooling2D(2, 2),\n    Dropout(0.25),\n    \n    # Fourth Conv Block\n    Conv2D(128, (3, 3), activation='relu'),\n    BatchNormalization(),\n    MaxPooling2D(2, 2),\n    Dropout(0.25),\n    \n    # Flatten and Dense Layers\n    Flatten(),\n    Dense(512, activation='relu'),\n    BatchNormalization(),\n    Dropout(0.5),\n    Dense(num_classes, activation='softmax')\n])\n\n# Compile the model\nmodel.compile(\n    optimizer=Adam(learning_rate=0.001),\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T02:37:22.316450Z","iopub.execute_input":"2025-09-25T02:37:22.316760Z","iopub.status.idle":"2025-09-25T02:37:22.527498Z","shell.execute_reply.started":"2025-09-25T02:37:22.316739Z","shell.execute_reply":"2025-09-25T02:37:22.526517Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 11: Train the model\n# Use GPU/TPU in Kaggle for faster training\nhistory = model.fit(\n    datagen.flow(X_train, y_train, batch_size=32),\n    steps_per_epoch=len(X_train) // 32,\n    epochs=20,  # Adjust based on time; start with 10-20\n    validation_data=(X_val, y_val),\n    verbose=1\n)\n\n# Plot training history\nplt.figure(figsize=(12, 4))\n\nplt.subplot(1, 2, 1)\nplt.plot(history.history['accuracy'], label='Train Accuracy')\nplt.plot(history.history['val_accuracy'], label='Val Accuracy')\nplt.title('Model Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(history.history['loss'], label='Train Loss')\nplt.plot(history.history['val_loss'], label='Val Loss')\nplt.title('Model Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T16:46:28.603655Z","iopub.execute_input":"2025-09-24T16:46:28.604022Z","iopub.status.idle":"2025-09-24T18:44:27.494122Z","shell.execute_reply.started":"2025-09-24T16:46:28.603988Z","shell.execute_reply":"2025-09-24T18:44:27.491796Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Step 12: Evaluate on validation set\nval_loss, val_accuracy = model.evaluate(X_val, y_val)\nprint(f\"Validation Accuracy: {val_accuracy:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T02:37:33.719006Z","iopub.execute_input":"2025-09-25T02:37:33.719522Z","iopub.status.idle":"2025-09-25T02:38:04.894882Z","shell.execute_reply.started":"2025-09-25T02:37:33.719494Z","shell.execute_reply":"2025-09-25T02:38:04.893751Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 13: Predict on test set\ntest_df = pd.read_csv(test_csv_path)\nprint(\"Test set shape:\", test_df.shape)\n\ntest_images = []\ntest_filenames = test_df['filename'].values  # Assuming column name is 'filename'\n\nprint(\"Loading and preprocessing test images...\")\nfor filename in test_filenames:\n    image_path = os.path.join(test_dir, filename)\n    result = load_and_preprocess_image(image_path, None)  # No label for test\n    if result is not None:\n        img, _ = result\n        test_images.append(img)\n\ntest_images = np.array(test_images)\nprint(f\"Loaded {len(test_images)} test images\")\n\n# Make predictions\npredictions = model.predict(test_images)\npredicted_classes = np.argmax(predictions, axis=1)\npredicted_labels = label_encoder.inverse_transform(predicted_classes)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T02:38:11.015675Z","iopub.execute_input":"2025-09-25T02:38:11.016016Z","iopub.status.idle":"2025-09-25T02:39:49.079842Z","shell.execute_reply.started":"2025-09-25T02:38:11.015989Z","shell.execute_reply":"2025-09-25T02:39:49.078382Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 14: Create submission CSV\nsubmission_df = pd.DataFrame({\n    'filename': test_filenames,\n    'label': predicted_labels\n})\nsubmission_df.to_csv('submission.csv', index=False)\nprint(\"Submission file 'submission.csv' created! Download and submit it to the competition.\")\n\n# Optional: Visualize some test predictions\nplt.figure(figsize=(12, 8))\nfor i in range(6):\n    plt.subplot(2, 3, i+1)\n    plt.imshow(test_images[i])\n    plt.title(f\"Predicted: {predicted_labels[i]}\")\n    plt.axis('off')\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T02:40:32.008039Z","iopub.execute_input":"2025-09-25T02:40:32.008506Z","iopub.status.idle":"2025-09-25T02:40:33.118502Z","shell.execute_reply.started":"2025-09-25T02:40:32.008471Z","shell.execute_reply":"2025-09-25T02:40:33.116979Z"}},"outputs":[],"execution_count":null}]}